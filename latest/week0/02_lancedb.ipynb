{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LanceDB\n",
    "\n",
    "> **Important**: It's important to note that we'll be using the local version of LanceDB in this course. This code can also work with the hosted version of LanceDB as long as you change the connection string to point to your LanceDB instance. \n",
    "\n",
    "LanceDB is a vector database that makes it easy to build and evaluate RAG applications. In this notebook, we'll explore how to use LanceDB's key features to store, search, and retrieve data effectively.\n",
    "\n",
    "## Why this Matters\n",
    "When building RAG systems, choosing the right vector database is crucial. While many options exist, LanceDB stands out by providing:\n",
    "\n",
    "1. Simple schema definition with Pydantic models\n",
    "2. Automatic embedding generation and management\n",
    "3. A unified API for different search types (vector, full-text, hybrid)\n",
    "\n",
    "## What you'll Learn\n",
    "\n",
    "Through hands-on examples, you'll discover how to:\n",
    "\n",
    "1. Set up LanceDB tables with proper schemas\n",
    "2. Perform different types of searches (full-text, vector, hybrid)\n",
    "3. Enhance results with reranking\n",
    "\n",
    "By the end of this notebook, you'll understand how to leverage LanceDB's capabilities to build robust retrieval systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up LanceDB\n",
    "\n",
    "We can create our LanceDB instance using the `lancedb` library and the `connect` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanceDBConnection(uri='/Users/ivanleo/Documents/coding/ttt/systematically-improving-rag/cohort_2/week0/lancedb')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lancedb\n",
    "\n",
    "db = lancedb.connect(\"./lancedb\")\n",
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should in turn create a `lancedb` directory in your current working directory. We can validate that this is the case by running the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.path.exists(\"./lancedb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create our first table. We'll do so by defining a Pydantic Schema and then using the `Table` class to create our table. We'll also use the OpenAI Embeddings API to create embeddings for these individual documents that we ingest. \n",
    "\n",
    "To read more about the different embedding models that are available for use, you can check out their documentation [here](https://lancedb.github.io/lancedb/embeddings/available_embedding_models/text_embedding_functions/). \n",
    "\n",
    "First let's define our Table schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "from lancedb.pydantic import LanceModel, Vector\n",
    "from lancedb.embeddings import get_registry\n",
    "\n",
    "\n",
    "func = get_registry().get(\"openai\").create(name=\"text-embedding-3-small\")\n",
    "\n",
    "\n",
    "# Define a Schema\n",
    "class Words(LanceModel):\n",
    "    # This is the source field that will be used as input to the OpenAI Embedding API\n",
    "    text: str = func.SourceField()\n",
    "\n",
    "    # This is the vector field that will store the output of the OpenAI Embedding API\n",
    "    vector: Vector(func.ndims()) = func.VectorField()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create our table with this schema. By using Pydantic, LanceDB will create the necessary fields for us and we can use the `add` method to ingest our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11T06:26:03Z WARN  lance::dataset::write::insert] No existing dataset at /Users/ivanleo/Documents/coding/ttt/systematically-improving-rag/cohort_2/week0/lancedb/words.lance, it will be created\n"
     ]
    }
   ],
   "source": [
    "table = db.create_table(\"words\", schema=Words, mode=\"overwrite\")\n",
    "\n",
    "# Ingest our data\n",
    "table.add([{\"text\": \"hello world\"}, {\"text\": \"goodbye world\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that our data was ingested correctly and that the embeddings were created by converting our table to a pandas dataframe and printing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hello world</td>\n",
       "      <td>[-0.006763331, -0.03919632, 0.034175806, 0.028...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>goodbye world</td>\n",
       "      <td>[0.025792664, -0.0054613473, 0.011670824, 0.01...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            text                                             vector\n",
       "0    hello world  [-0.006763331, -0.03919632, 0.034175806, 0.028...\n",
       "1  goodbye world  [0.025792664, -0.0054613473, 0.011670824, 0.01..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with that we've created our first table in LanceDB! Now we'll walk through how to do full text search with our table. This is a simple method which provides a strong baseline for our retrieval system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Text Search\n",
    "\n",
    "> **Important** : Before running this code, make sure you've installed `tantivy==0.20.1` in your local kernel. This is important because LanceDB uses Tantivy under the hood to perform FTS.\n",
    "\n",
    "By default, LanceDB uses vector search to perform any query, This means that when we query our table, it'll use the vector embeddings to find the most similar documents to our query.\n",
    "\n",
    "In order to use Full Text Search instead, we need to explicitly set the query type to `fts` in order for it to work. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "lance error: Invalid user input: Cannot perform full text search unless an INVERTED index has been created on at least one column, /Users/runner/.cargo/registry/src/index.crates.io-6f17d22bba15001f/lance-0.22.0/src/dataset/scanner.rs:1515:17",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhello\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/coding/ttt/systematically-improving-rag/cohort_2/.venv/lib/python3.9/site-packages/lancedb/query.py:327\u001b[0m, in \u001b[0;36mLanceQueryBuilder.to_list\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_list\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mdict\u001b[39m]:\n\u001b[1;32m    320\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;124;03m    Execute the query and return the results as a list of dictionaries.\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m    fields are returned whether or not they're explicitly selected.\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_pylist()\n",
      "File \u001b[0;32m~/Documents/coding/ttt/systematically-improving-rag/cohort_2/.venv/lib/python3.9/site-packages/lancedb/query.py:905\u001b[0m, in \u001b[0;36mLanceFtsQueryBuilder.to_arrow\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    888\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    889\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPhrase query is not yet supported in Lance FTS. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    890\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse tantivy-based index instead for now.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    891\u001b[0m     )\n\u001b[1;32m    892\u001b[0m query \u001b[38;5;241m=\u001b[39m Query(\n\u001b[1;32m    893\u001b[0m     columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_columns,\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_where,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    903\u001b[0m     offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset,\n\u001b[1;32m    904\u001b[0m )\n\u001b[0;32m--> 905\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    906\u001b[0m results \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mread_all()\n\u001b[1;32m    907\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reranker \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/coding/ttt/systematically-improving-rag/cohort_2/.venv/lib/python3.9/site-packages/lancedb/table.py:2138\u001b[0m, in \u001b[0;36mLanceTable._execute_query\u001b[0;34m(self, query, batch_size)\u001b[0m\n\u001b[1;32m   2135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_execute_query\u001b[39m(\n\u001b[1;32m   2136\u001b[0m     \u001b[38;5;28mself\u001b[39m, query: Query, batch_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2137\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pa\u001b[38;5;241m.\u001b[39mRecordBatchReader:\n\u001b[0;32m-> 2138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLOOP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/coding/ttt/systematically-improving-rag/cohort_2/.venv/lib/python3.9/site-packages/lancedb/background_loop.py:25\u001b[0m, in \u001b[0;36mBackgroundEventLoop.run\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_coroutine_threadsafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:445\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:390\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/coding/ttt/systematically-improving-rag/cohort_2/.venv/lib/python3.9/site-packages/lancedb/table.py:2886\u001b[0m, in \u001b[0;36mAsyncTable._execute_query\u001b[0;34m(self, query, batch_size)\u001b[0m\n\u001b[1;32m   2883\u001b[0m     fts_columns \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39mfull_text_query\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m, []) \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m   2884\u001b[0m     async_query \u001b[38;5;241m=\u001b[39m async_query\u001b[38;5;241m.\u001b[39mnearest_to_text(fts_query, columns\u001b[38;5;241m=\u001b[39mfts_columns)\n\u001b[0;32m-> 2886\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m async_query\u001b[38;5;241m.\u001b[39mto_arrow()\n\u001b[1;32m   2887\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39mto_reader()\n",
      "File \u001b[0;32m~/Documents/coding/ttt/systematically-improving-rag/cohort_2/.venv/lib/python3.9/site-packages/lancedb/query.py:1895\u001b[0m, in \u001b[0;36mAsyncFTSQuery.to_arrow\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1894\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_arrow\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pa\u001b[38;5;241m.\u001b[39mTable:\n\u001b[0;32m-> 1895\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mto_arrow()\n\u001b[1;32m   1896\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reranker:\n\u001b[1;32m   1897\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reranker\u001b[38;5;241m.\u001b[39mrerank_fts(results)\n",
      "File \u001b[0;32m~/Documents/coding/ttt/systematically-improving-rag/cohort_2/.venv/lib/python3.9/site-packages/lancedb/query.py:1567\u001b[0m, in \u001b[0;36mAsyncQueryBase.to_arrow\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_arrow\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pa\u001b[38;5;241m.\u001b[39mTable:\n\u001b[1;32m   1560\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1561\u001b[0m \u001b[38;5;124;03m    Execute the query and collect the results into an Apache Arrow Table.\u001b[39;00m\n\u001b[1;32m   1562\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1565\u001b[0m \u001b[38;5;124;03m    [to_batches][lancedb.query.AsyncQueryBase.to_batches]\u001b[39;00m\n\u001b[1;32m   1566\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1567\u001b[0m     batch_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_batches()\n\u001b[1;32m   1568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mTable\u001b[38;5;241m.\u001b[39mfrom_batches(\n\u001b[1;32m   1569\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m batch_iter\u001b[38;5;241m.\u001b[39mread_all(), schema\u001b[38;5;241m=\u001b[39mbatch_iter\u001b[38;5;241m.\u001b[39mschema\n\u001b[1;32m   1570\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/coding/ttt/systematically-improving-rag/cohort_2/.venv/lib/python3.9/site-packages/lancedb/query.py:1557\u001b[0m, in \u001b[0;36mAsyncQueryBase.to_batches\u001b[0;34m(self, max_batch_length)\u001b[0m\n\u001b[1;32m   1542\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_batches\u001b[39m(\n\u001b[1;32m   1543\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, max_batch_length: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1544\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncRecordBatchReader:\n\u001b[1;32m   1545\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1546\u001b[0m \u001b[38;5;124;03m    Execute the query and return the results as an Apache Arrow RecordBatchReader.\u001b[39;00m\n\u001b[1;32m   1547\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1555\u001b[0m \u001b[38;5;124;03m        underlying data is stored in smaller chunks.\u001b[39;00m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m AsyncRecordBatchReader(\u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner\u001b[38;5;241m.\u001b[39mexecute(max_batch_length))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: lance error: Invalid user input: Cannot perform full text search unless an INVERTED index has been created on at least one column, /Users/runner/.cargo/registry/src/index.crates.io-6f17d22bba15001f/lance-0.22.0/src/dataset/scanner.rs:1515:17"
     ]
    }
   ],
   "source": [
    "table.search(\"hello\", query_type=\"fts\").to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But when we run the code above, we get the error that an inverted index is not found. This is a valid error because in order for us to perform full text search, we need to create an index which maps keywords to the documents that contain them.\n",
    "\n",
    "### What is an Inverted Index?\n",
    "\n",
    "An inverted index is a data structure that allows us to quickly look up which documents contain a given keyword. It's a key component of full text search systems and is used to speed up the search process.\n",
    "\n",
    "it maps words or subwords to the documents that contain them. We need to generate this ahead of time so that we can perform full text search efficiently. \n",
    "\n",
    "Let's see a simplified example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have an initial document\n",
    "documents = {\n",
    "    1: \"The quick brown fox\",\n",
    "    2: \"The lazy brown dog\",\n",
    "    3: \"The fox jumps over dog\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might then do some pre-processing here to break down the contents of each documents into subwords or words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = {\n",
    "    \"the\": {1, 2, 3},\n",
    "    \"quick\": {1},\n",
    "    \"brown\": {1, 2},\n",
    "    \"fox\": {1, 3},\n",
    "    \"lazy\": {2},\n",
    "    \"dog\": {2, 3},\n",
    "    \"jumps\": {3},\n",
    "    \"over\": {3},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that when users make a query like `the dog`, we can quickly look up the documents that contain these words and return the results. \n",
    "\n",
    "We use a simplified implementation here we check for each word in the query and then return the documents that contain any of the words. A document that has more matches has a higher score and will be ranked higher in the returned results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Search results: <span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'doc_id'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'doc_id'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'doc_id'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span><span style=\"font-weight: bold\">}]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Search results: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'doc_id'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'score'\u001b[0m: \u001b[1;36m1.0\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'doc_id'\u001b[0m: \u001b[1;36m2\u001b[0m, \u001b[32m'score'\u001b[0m: \u001b[1;36m0.5\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'doc_id'\u001b[0m: \u001b[1;36m3\u001b[0m, \u001b[32m'score'\u001b[0m: \u001b[1;36m0.5\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def search(query, inverted_index):\n",
    "    # Convert query to lowercase and split into words\n",
    "    query_words = query.lower().split()\n",
    "\n",
    "    # Count matches for each document\n",
    "    doc_scores = {}\n",
    "    for word in query_words:\n",
    "        if word in inverted_index:\n",
    "            for doc_id in inverted_index[word]:\n",
    "                doc_scores[doc_id] = doc_scores.get(doc_id, 0) + 1\n",
    "\n",
    "    # Sort documents by score in descending order\n",
    "    sorted_results = sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Return list of (doc_id, score) tuples\n",
    "    return [\n",
    "        {\"doc_id\": doc_id, \"score\": score / len(query_words)}\n",
    "        for doc_id, score in sorted_results\n",
    "    ]\n",
    "\n",
    "\n",
    "query = \"the quick\"\n",
    "results = search(query, inverted_index)\n",
    "print(f\"Search results: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LanceDB automates this process for us and makes it incredibly easy to perform full text search with the `create_fts_index` method. A few things are different here, they use a scoring mechanism called `BM25` and more pre-processing is done for both your queries and documents themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.create_fts_index(\"text\", replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that our full text search works nicely out of the box now. Additionally with Tantivy, we can use boolean queries to combine multiple words as seen below where we combine `hello` and `goodbye` in our query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">hello world\n",
       "</pre>\n"
      ],
      "text/plain": [
       "hello world\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in table.search(\"hello\", query_type=\"fts\").to_list():\n",
    "    print(item[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">hello world\n",
       "</pre>\n"
      ],
      "text/plain": [
       "hello world\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">goodbye world\n",
       "</pre>\n"
      ],
      "text/plain": [
       "goodbye world\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in table.search(\"hello OR goodbye\", query_type=\"fts\").to_list():\n",
    "    print(item[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Different Retrieval Methods\n",
    "\n",
    "Let's quickly review the different retrieval methods that we've seen so far.\n",
    "\n",
    "1. **Vector Search** : Vector Search converts text into number sequences (vectors) that capture meaning. When you search, it finds documents whose vectors are closest to your query vector. This works well for finding semantically similar content, even if the exact words don't match. For example, \"I'm delighted\" and \"I'm really happy\" would be considered similar.\n",
    "2. **Full text Search** : Full Text Search directly matches the words in your query to words in documents. It uses techniques like BM25 scoring, which ranks documents based on how often your search terms appear and how unique those terms are across all documents. This is great for finding exact matches or specific keywords.\n",
    "3. **Hybrid Search** : Hybrid Search combines both approaches to get the best of both worlds. It can find documents that either contain your exact keywords or express similar meanings. We make a query using both search results and then combine the final set of retrieved results in a given way to return a new set of results.\n",
    "\n",
    "Let's see how we can perform hybrid search in LanceDB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">hello world\n",
       "</pre>\n"
      ],
      "text/plain": [
       "hello world\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">goodbye world\n",
       "</pre>\n"
      ],
      "text/plain": [
       "goodbye world\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in table.search(\"I'm really excited!\", query_type=\"hybrid\").to_list():\n",
    "    print(item[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the results are semantically similar to our query. Hello World is much closer to say \"I'm really excited!\" than Goodbye World. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Re-Rankers\n",
    "\n",
    "While basic search methods work well for simple queries, more complex questions often benefit from re-ranking. \n",
    "\n",
    "A re-ranker takes an initial set of search results and applies a more sophisticated model to analyze how well each result actually answers your query. \n",
    "\n",
    "For example, in our capital punishment example below, hybrid search returns documents that contain the relevant keywords. But the re-ranker can better understand we're asking about location rather than general information, helping it prioritize the Washington D.C. result. This additional analysis takes more computation time but often produces significantly better results for complex queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's create some more complex documents\n",
    "documents = [\n",
    "    \"Carson City is the capital city of the American state of Nevada.\",\n",
    "    \"The Commonwealth of the Northern Mariana Islands is a group of islands in the Pacific Ocean. Its capital is Saipan.\",\n",
    "    \"Washington, D.C. (also known as simply Washington or D.C., and officially as the District of Columbia) is the capital of the United States. It is a federal district. \",\n",
    "    \"Capital punishment (the death penalty) has existed in the United States since before the United States was a country. As of 2017, capital punishment is legal in 30 of the 50 states.\",\n",
    "]\n",
    "documents = [{\"text\": doc} for doc in documents]\n",
    "\n",
    "# Create a new table for our complex documents\n",
    "complex_table = db.create_table(\"complex_docs\", data=documents, schema=Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an index for full text search\n",
    "complex_table.create_fts_index([\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Capital punishment <span style=\"font-weight: bold\">(</span>the death penalty<span style=\"font-weight: bold\">)</span> has existed in the United States since before the United States was a \n",
       "country. As of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2017</span>, capital punishment is legal in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> of the <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> states.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36m1\u001b[0m. Capital punishment \u001b[1m(\u001b[0mthe death penalty\u001b[1m)\u001b[0m has existed in the United States since before the United States was a \n",
       "country. As of \u001b[1;36m2017\u001b[0m, capital punishment is legal in \u001b[1;36m30\u001b[0m of the \u001b[1;36m50\u001b[0m states.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. Washington, D.C. <span style=\"font-weight: bold\">(</span>also known as simply Washington or D.C., and officially as the District of Columbia<span style=\"font-weight: bold\">)</span> is the \n",
       "capital of the United States. It is a federal district. \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36m2\u001b[0m. Washington, D.C. \u001b[1m(\u001b[0malso known as simply Washington or D.C., and officially as the District of Columbia\u001b[1m)\u001b[0m is the \n",
       "capital of the United States. It is a federal district. \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. Carson City is the capital city of the American state of Nevada.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36m3\u001b[0m. Carson City is the capital city of the American state of Nevada.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. The Commonwealth of the Northern Mariana Islands is a group of islands in the Pacific Ocean. Its capital is \n",
       "Saipan.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36m4\u001b[0m. The Commonwealth of the Northern Mariana Islands is a group of islands in the Pacific Ocean. Its capital is \n",
       "Saipan.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's try a search query and see the results before reranking\n",
    "query = \"where did the capital of the United States decide to allow capital punishment?\"\n",
    "\n",
    "results = complex_table.search(query, query_type=\"hybrid\").limit(4).to_list()\n",
    "for idx, item in enumerate(results):\n",
    "    print(f\"\\n{idx + 1}. {item['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good start but we can see that the results are not exactly what we want. We're asking for a location where the capital punishment decision was made instead of when capital punishment was allowed.\n",
    "\n",
    "In this case we can solve this by using a `ReRanker`. Re-rankers are more expensive than just doing simple vector search but they often allow us to improve the results of our retrieval system by a large margin.\n",
    "\n",
    "We can use the `rerank` method in LanceDB to re-rank our results. We'll use the `CohereReranker` to do so. We'll also use the `rerank_top_k` parameter to limit the number of results that we return.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Washington, D.C. <span style=\"font-weight: bold\">(</span>also known as simply Washington or D.C., and officially as the District of Columbia<span style=\"font-weight: bold\">)</span> is the \n",
       "capital of the United States. It is a federal district. \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36m1\u001b[0m. Washington, D.C. \u001b[1m(\u001b[0malso known as simply Washington or D.C., and officially as the District of Columbia\u001b[1m)\u001b[0m is the \n",
       "capital of the United States. It is a federal district. \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. Capital punishment <span style=\"font-weight: bold\">(</span>the death penalty<span style=\"font-weight: bold\">)</span> has existed in the United States since before the United States was a \n",
       "country. As of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2017</span>, capital punishment is legal in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> of the <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> states.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36m2\u001b[0m. Capital punishment \u001b[1m(\u001b[0mthe death penalty\u001b[1m)\u001b[0m has existed in the United States since before the United States was a \n",
       "country. As of \u001b[1;36m2017\u001b[0m, capital punishment is legal in \u001b[1;36m30\u001b[0m of the \u001b[1;36m50\u001b[0m states.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. Carson City is the capital city of the American state of Nevada.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36m3\u001b[0m. Carson City is the capital city of the American state of Nevada.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. The Commonwealth of the Northern Mariana Islands is a group of islands in the Pacific Ocean. Its capital is \n",
       "Saipan.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36m4\u001b[0m. The Commonwealth of the Northern Mariana Islands is a group of islands in the Pacific Ocean. Its capital is \n",
       "Saipan.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lancedb.rerankers import CohereReranker\n",
    "\n",
    "# Let's try a search query and see the results before reranking\n",
    "query = \"where did the capital of the United States decide to allow capital punishment?\"\n",
    "\n",
    "# Then Define a Cohere Reranker\n",
    "reranker = CohereReranker(model_name=\"rerank-english-v3.0\")\n",
    "\n",
    "results = (\n",
    "    complex_table.search(query, query_type=\"hybrid\").rerank(reranker).limit(4).to_list()\n",
    ")\n",
    "for idx, item in enumerate(results):\n",
    "    print(f\"\\n{idx + 1}. {item['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've explored the core features that make LanceDB well-suited for RAG applications. We learned how to:\n",
    "\n",
    "1. Define clean schemas using Pydantic models\n",
    "2. Index and search data using different methods\n",
    "3. Leverage the Re-Ranking API to improve the results of our retrieval system\n",
    "\n",
    "LanceDB's combination of type safety through Pydantic, automated embedding handling, and unified search API provides a strong foundation for RAG development. These capabilities will be especially valuable in future weeks as we evaluate and improve different aspects of our retrieval system. Understanding these LanceDB basics ensures you can follow along with the rest of the course and make the most out of it.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
