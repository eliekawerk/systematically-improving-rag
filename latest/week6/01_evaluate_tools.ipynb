{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 - Systematically Improving Your Rag Application\n",
    "\n",
    "In this notebook, we'll explore how to evaluate the ability of a model to select the right tools for a given user query by measuring precision and recall.\n",
    "\n",
    "## Why this matters\n",
    "\n",
    "As RAG systems grow more complex, they often need to coordinate multiple tools - from searching documentation to querying databases to sending notifications. Without objective metrics to evaluate tool selection, we risk calling unnecessary tools (wasting resources) or missing critical ones (degrading user experience).\n",
    "\n",
    "While traditional RAG evaluation focuses on retrieval quality, tool selection requires its own framework. A model might find relevant content but fail to take the right actions with it. By measuring precision and recall of tool selection, we can systematically improve how our models coordinate multiple tools.\n",
    "\n",
    "## What you'll learn\n",
    "\n",
    "Through hands-on examples using a personal assistant chatbot, you'll discover how to:\n",
    "\n",
    "1. Measure Tool Selection Quality\n",
    "- Understand what precision and recall mean for tool calls\n",
    "- Create clear test cases to evaluate tool selection\n",
    "- Visualize and analyze tool selection performance\n",
    "\n",
    "2. Implement Evaluation Methods\n",
    "- Convert precision and recall into code\n",
    "- Write unit tests for tool selection accuracy\n",
    "- Track performance across different queries\n",
    "\n",
    "3. Compare Tool Selection Approaches\n",
    "- Evaluate parallel vs sequential tool calling\n",
    "- Measure tradeoffs in accuracy and speed\n",
    "- Make data-driven decisions about tool selection methods\n",
    "\n",
    "\n",
    "By the end of this notebook, you'll have a framework for measuring and improving how accurately your models select tools as well as how to quantitatively measure the impact of specific changes to your tool calling strategy.\n",
    "\n",
    "## Raycast Natural Language Extensions\n",
    "\n",
    "Raycast is an application which enables you to launch custom shortcuts and integrations on your computer. It combines a variety of different integrations with tools such as Jira, Airtable, Google among many others and will be launching an easy way to help prompt extensions with natural language.\n",
    "\n",
    "For instance, given the command `@calendar when's my next meeting?`, Raycast will be able to execute a series of commands that you have installed which will fetch all of your meetings and then return your next meeting timing after the current time. This will allow users to be able to interact with their system quickly and effeciently. \n",
    "\n",
    "In this notebook series, we'll look at how we might prototype a similar application. We'll do so over 3 notebooks.\n",
    "\n",
    "1. **Evaluating Tool Calling ability**: Using a simple set of tools, we'll calculate precision and recall and see how to use these two metrics to evaluate the tools a model has called relative to a set of expected tool calls.\n",
    "\n",
    "2. **Creating a Dataset** : We'll first examine some failure modes that models experience when it comes to tool calling and how we might generate a synthetic dataset to cover these failure cases. We'll then generate an initial set of queries that mimic these failure cases and then use them to generate a larger synthetic dataset of queries. While doing so, we'll use `braintrust` to evaluate the performance of our model's tool calling ability and establish an initial baseline\n",
    "\n",
    "3. **Improvement** : Once we've done so, we'll explore different techniques that we can use to improve the performance of our model's tool calling ability such as few shot examples and system prompts provided by users. We'll then compare these against our original baseline and use the same techniques to evaluate the performance of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Model Performance\n",
    "\n",
    "In this section, we'll be looking at how we can evaluate the performance of a model to call the right tool. We'll do so in 3 steps\n",
    "\n",
    "1. **Metrics** : We'll first look at precision and recall and why we want to use them to evaluate our model's performance\n",
    "2. **Tool Calling** : We'll then see how we can evalute the performance of our model using these metrics by writing simple assertions and unit tests\n",
    "3. **Parallel Tool Calling**: We'll then see how we can leverage parallel tool calling to improve the latency of our application and improve the performance of our model\n",
    "\n",
    "\n",
    "\n",
    "### Precision and Recall\n",
    "\n",
    "We want to evaluate how well our model performs when it comes to calling tools. In order to do so, we'll be using two main metrics\n",
    "\n",
    "1. Precision : Precision tells us what fraction of the tools we called were actualy useful. A high precision means we avoid wasting resources on calling irrelevant tools.\n",
    "2. Recall : Recall tells us what fraction of the relevant tools we actually used. A high recall means we're not missing important steps that the user needs.\n",
    "\n",
    "Balancing these two metrics is critical. If we only focus on recall, the model might call too many toolsâ€”most of which are unnecessary. If we only focus on precision, then we might miss out on potential tools that the user needs. \n",
    "\n",
    "Let's now see how we can manually calculate these metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.33, 1.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tools that our model called\n",
    "model_tool_call = [\n",
    "    \"GET_CALENDAR_EVENTS\",\n",
    "    \"CREATE_REMINDER\",\n",
    "    \"SEND_EMAIL\",\n",
    "]\n",
    "\n",
    "# Tools that we expected our model to call\n",
    "expected_tool_call = [\n",
    "    \"GET_CALENDAR_EVENTS\",\n",
    "]\n",
    "\n",
    "\n",
    "def calculate_precision(model_tool_call, expected_tool_call):\n",
    "    if len(model_tool_call) == 0:\n",
    "        return 0\n",
    "\n",
    "    relevant_results = sum(1 for tool in model_tool_call if tool in expected_tool_call)\n",
    "    return round(relevant_results / len(model_tool_call), 2)\n",
    "\n",
    "\n",
    "def calculate_recall(model_tool_call, expected_tool_call):\n",
    "    if len(expected_tool_call) == 0:\n",
    "        return 1\n",
    "\n",
    "    if len(model_tool_call) == 0:\n",
    "        return 0\n",
    "\n",
    "    relevant_results = sum(1 for tool in expected_tool_call if tool in model_tool_call)\n",
    "    return round(relevant_results / len(expected_tool_call), 2)\n",
    "\n",
    "\n",
    "precision, recall = (\n",
    "    calculate_precision(model_tool_call, expected_tool_call),\n",
    "    calculate_recall(model_tool_call, expected_tool_call),\n",
    ")\n",
    "\n",
    "precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for this specific case, we had two tools that were called that were irrelevant to the user's query - `CREATE_REMINDER` and `SEND_EMAIL`. For a production application, we'd want to avoid this.\n",
    "\n",
    "We did achieve a perfect recall - but remember here that a perfect recall can also be achieved by calling every single tool in our application. We want to minimise the amount of wasted computation. Let's see another example of how to compute these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tools that our model called\n",
    "model_tool_call = [\n",
    "    \"GET_CALENDAR_EVENTS\",\n",
    "]\n",
    "\n",
    "# Tools that we expected our model to call\n",
    "expected_tool_call = [\n",
    "    \"GET_CALENDAR_EVENTS\",\n",
    "    \"CREATE_REMINDER\",\n",
    "]\n",
    "\n",
    "precision, recall = (\n",
    "    calculate_precision(model_tool_call, expected_tool_call),\n",
    "    calculate_recall(model_tool_call, expected_tool_call),\n",
    ")\n",
    "\n",
    "precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we have a slightly lower recall of 0.5 here because we didn't call the `CREATE_REMINDER` tool, we have a higher precision of 1. This is preferable to the previous case where we called two irrelevant tools.\n",
    "\n",
    "Therefore, what we want to do is to maximise precision while keeping recall high. This means that we ideally want to make sure that **all of our tools called are relevant** while making sure that we **call as many of the relevant tools as possible**. This is quite distinct from RAG where we want to amximise recall while relying on the model's ability to filter out irrelevant information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining our Tools\n",
    "\n",
    "We want to have a set of test cases that we can use to evaluate the performance of our model. We want to use them to measure the precision and recall of our model's tool calling in response to a user query. \n",
    "\n",
    "To demonstrate how we can do so, we'll do so in 3 steps below\n",
    "\n",
    "1. We'll first define some tools that a simple personal assistant chatbot might use\n",
    "2. We'll then define a set of test cases and corresponding expected tool calls\n",
    "3. Lastly, we'll evaluate how well our model performs on these test cases using simple precision and recall metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "class SendEmail(BaseModel):\n",
    "    email: str\n",
    "    subject: str\n",
    "    body: str\n",
    "\n",
    "\n",
    "class GetCalendarEvents(BaseModel):\n",
    "    calendar: list[Literal[\"work\", \"personal\"]]\n",
    "    start_date: datetime = Field(default_factory=datetime.now)\n",
    "    end_date: datetime = Field(\n",
    "        default_factory=lambda: datetime.now() + timedelta(days=7)\n",
    "    )\n",
    "\n",
    "\n",
    "class CreateReminder(BaseModel):\n",
    "    title: str\n",
    "    description: str\n",
    "    due_date: datetime\n",
    "\n",
    "\n",
    "class ToolCalls(BaseModel):\n",
    "    calls: list[\n",
    "        Union[\n",
    "            SendEmail,\n",
    "            GetCalendarEvents,\n",
    "            CreateReminder,\n",
    "        ]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "from openai import AsyncOpenAI\n",
    "from asyncio import Semaphore, get_running_loop\n",
    "import time\n",
    "\n",
    "\n",
    "client = instructor.from_openai(AsyncOpenAI())\n",
    "\n",
    "\n",
    "async def generate_tool_calls(query: str, sem: Semaphore):\n",
    "    async with sem:\n",
    "        start = get_running_loop().time()\n",
    "        resp = await client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": f\"You are a helpful assistant that can call tools in response to user requests. Today's date is {datetime.now().strftime('%Y-%m-%d')}\",\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": query},\n",
    "            ],\n",
    "            response_model=ToolCalls,\n",
    "        )\n",
    "        end = get_running_loop().time()\n",
    "        return {\n",
    "            \"response\": resp,\n",
    "            \"time\": end - start,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "tests = [\n",
    "    # Single tool queries\n",
    "    [\"Send an email to john@example.com about the project update\", [SendEmail]],\n",
    "    [\"What meetings do I have scheduled for tomorrow?\", [GetCalendarEvents]],\n",
    "    [\"Set a reminder for my dentist appointment next week\", [CreateReminder]],\n",
    "    # Two tool combinations\n",
    "    [\n",
    "        \"Check my calendar for next week's meetings and set reminders for each one\",\n",
    "        [GetCalendarEvents, CreateReminder],\n",
    "    ],\n",
    "    [\n",
    "        \"Look up my team meeting schedule and send the agenda to all participants\",\n",
    "        [GetCalendarEvents, SendEmail],\n",
    "    ],\n",
    "    [\n",
    "        \"Set a reminder for the client call and send a confirmation email to the team\",\n",
    "        [CreateReminder, SendEmail],\n",
    "    ],\n",
    "]\n",
    "\n",
    "sem = asyncio.Semaphore(10)\n",
    "coros = [generate_tool_calls(query, sem) for query, _ in tests]\n",
    "\n",
    "results = await asyncio.gather(*coros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>expected</th>\n",
       "      <th>actual</th>\n",
       "      <th>time</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>CORRECT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Send an email to john@example.com about the pr...</td>\n",
       "      <td>[SendEmail]</td>\n",
       "      <td>[SendEmail]</td>\n",
       "      <td>2.57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What meetings do I have scheduled for tomorrow?</td>\n",
       "      <td>[GetCalendarEvents]</td>\n",
       "      <td>[GetCalendarEvents]</td>\n",
       "      <td>1.81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Set a reminder for my dentist appointment next...</td>\n",
       "      <td>[CreateReminder]</td>\n",
       "      <td>[CreateReminder]</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Check my calendar for next week's meetings and...</td>\n",
       "      <td>[GetCalendarEvents, CreateReminder]</td>\n",
       "      <td>[GetCalendarEvents]</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Look up my team meeting schedule and send the ...</td>\n",
       "      <td>[GetCalendarEvents, SendEmail]</td>\n",
       "      <td>[GetCalendarEvents]</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Set a reminder for the client call and send a ...</td>\n",
       "      <td>[CreateReminder, SendEmail]</td>\n",
       "      <td>[SendEmail, CreateReminder]</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Send an email to john@example.com about the pr...   \n",
       "1    What meetings do I have scheduled for tomorrow?   \n",
       "2  Set a reminder for my dentist appointment next...   \n",
       "3  Check my calendar for next week's meetings and...   \n",
       "4  Look up my team meeting schedule and send the ...   \n",
       "5  Set a reminder for the client call and send a ...   \n",
       "\n",
       "                              expected                       actual  time  \\\n",
       "0                          [SendEmail]                  [SendEmail]  2.57   \n",
       "1                  [GetCalendarEvents]          [GetCalendarEvents]  1.81   \n",
       "2                     [CreateReminder]             [CreateReminder]  1.65   \n",
       "3  [GetCalendarEvents, CreateReminder]          [GetCalendarEvents]  1.78   \n",
       "4       [GetCalendarEvents, SendEmail]          [GetCalendarEvents]  0.87   \n",
       "5          [CreateReminder, SendEmail]  [SendEmail, CreateReminder]  2.51   \n",
       "\n",
       "   precision  recall CORRECT  \n",
       "0        1.0     1.0       Y  \n",
       "1        1.0     1.0       Y  \n",
       "2        1.0     1.0       Y  \n",
       "3        1.0     0.5       N  \n",
       "4        1.0     0.5       N  \n",
       "5        1.0     1.0       Y  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def calculate_precision_recall_for_queries(df):\n",
    "    df = df.copy()\n",
    "    df[\"precision\"] = df.apply(\n",
    "        lambda x: calculate_precision(x[\"actual\"], x[\"expected\"]), axis=1\n",
    "    )\n",
    "    df[\"recall\"] = df.apply(\n",
    "        lambda x: calculate_recall(x[\"actual\"], x[\"expected\"]), axis=1\n",
    "    )\n",
    "    df[\"CORRECT\"] = df.apply(\n",
    "        lambda x: \"Y\" if set(x[\"expected\"]) == set(x[\"actual\"]) else \"N\", axis=1\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"query\": test_item[0],\n",
    "            \"expected\": [tool.__name__ for tool in test_item[1]],\n",
    "            \"actual\": list(\n",
    "                set([type(tool).__name__ for tool in result[\"response\"].calls])\n",
    "            ),\n",
    "            \"time\": round(result[\"time\"], 2),\n",
    "        }\n",
    "        for test_item, result in zip(tests, results)\n",
    "    ]\n",
    ")\n",
    "df = calculate_precision_recall_for_queries(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recall       0.83\n",
       "precision    1.00\n",
       "time         1.86\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"recall\", \"precision\", \"time\"]].mean().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a few things here \n",
    "\n",
    "1. In general, our model has a high precision - this means that when it decides to call a tool, it's almost always relevant to the user's query. \n",
    "2. It has a low recall when we combine certain tools together. In this case, it struggled with the query - `look at my team meeting schedule and send the agenda to all participants` and struggled to understand that it should call the `GetCalendarEvents` and `SendEmail` tools together.\n",
    "\n",
    "We can go one step further and segment questions by examining the recall per class. We want to do so because it allows us to identify specific classes of tool(s) that our model struggles with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tool</th>\n",
       "      <th>actual</th>\n",
       "      <th>expected</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SendEmail</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CreateReminder</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GetCalendarEvents</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tool  actual  expected  recall\n",
       "0          SendEmail       1         3    0.33\n",
       "1     CreateReminder       1         3    0.33\n",
       "2  GetCalendarEvents       2         3    0.67"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_per_tool_recall(df):\n",
    "    \"\"\"\n",
    "    This assumes that we have a dataframe with the columns expected and actual that correspond to the expected and actual tool calls respectively.\n",
    "    \"\"\"\n",
    "    # Get all unique tools\n",
    "    all_tools = set()\n",
    "    for tools in df[\"expected\"] + df[\"actual\"]:\n",
    "        all_tools.update(tools)\n",
    "\n",
    "    occurences = {tool: 0 for tool in all_tools}\n",
    "    expected_occurences = {tool: 0 for tool in all_tools}\n",
    "\n",
    "    # Count occurrences for each individual tool\n",
    "    for _, row in df.iterrows():\n",
    "        expected_tools = set(row[\"expected\"])\n",
    "        actual_tools = set(row[\"actual\"])\n",
    "\n",
    "        for tool in expected_tools:\n",
    "            expected_occurences[tool] += 1\n",
    "\n",
    "        for tool in actual_tools:\n",
    "            if tool in expected_tools:\n",
    "                occurences[tool] += 1\n",
    "\n",
    "    # Calculate per-tool recall\n",
    "    per_tool_recall = []\n",
    "    for tool in all_tools:\n",
    "        per_tool_recall.append(\n",
    "            {\n",
    "                \"tool\": tool,\n",
    "                \"actual\": occurences[tool],\n",
    "                \"expected\": expected_occurences[tool],\n",
    "                \"recall\": occurences[tool] / expected_occurences[tool],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(per_tool_recall).round(2)\n",
    "\n",
    "\n",
    "# Call the function with our dataframe\n",
    "calculate_per_tool_recall(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Tool Calling\n",
    "\n",
    "In our previous example, we needed to wait for an entire response from the model to call our tools. This meant that each tool needs to wait for prior tool calls to complete before it can be generated.\n",
    "\n",
    "With Parallel tool calling, we can sidestep and generate multiple tool calls in a single request. We can benchmark and determine the impact of this improvement in latency on our model performance with our evals.\n",
    "\n",
    "Let's see how we can do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GetCalendarEvents</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">calendar</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'work'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'personal'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">start_date</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">datetime</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.datetime</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">end_date</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">datetime</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.datetime</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mGetCalendarEvents\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcalendar\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'work'\u001b[0m, \u001b[32m'personal'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mstart_date\u001b[0m=\u001b[1;35mdatetime\u001b[0m\u001b[1;35m.datetime\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2025\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mend_date\u001b[0m=\u001b[1;35mdatetime\u001b[0m\u001b[1;35m.datetime\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2025\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m11\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SendEmail</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">email</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'john@example.com'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">subject</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Meeting Reminder for Tomorrow'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">body</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Hi John,\\n\\nJust a reminder about our meeting scheduled for tomorrow. Looking forward to our </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">discussion.\\n\\nBest,\\n[Your Name]'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mSendEmail\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33memail\u001b[0m=\u001b[32m'john@example.com'\u001b[0m,\n",
       "    \u001b[33msubject\u001b[0m=\u001b[32m'Meeting Reminder for Tomorrow'\u001b[0m,\n",
       "    \u001b[33mbody\u001b[0m=\u001b[32m'Hi John,\\n\\nJust a reminder about our meeting scheduled for tomorrow. Looking forward to our \u001b[0m\n",
       "\u001b[32mdiscussion.\\n\\nBest,\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mYour Name\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import openai\n",
    "import instructor\n",
    "from typing import Iterable, Union\n",
    "from rich import print\n",
    "\n",
    "client = instructor.from_openai(\n",
    "    openai.AsyncOpenAI(), mode=instructor.Mode.PARALLEL_TOOLS\n",
    ")\n",
    "\n",
    "function_calls = await client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"You must always use tools. Today's date is {datetime.now().strftime('%Y-%m-%d')}\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Can you fetch my calendar events for the next week and send an email to John(john@example.com) about the meeting we have tomorrow?\",\n",
    "        },\n",
    "    ],\n",
    "    response_model=Iterable[Union[GetCalendarEvents, SendEmail, CreateReminder]],\n",
    ")\n",
    "\n",
    "for fc in function_calls:\n",
    "    print(fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now see how we can adopt our previous unit test to evaluate the performance of our model with parallel tool calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Union\n",
    "\n",
    "client = instructor.from_openai(AsyncOpenAI(), mode=instructor.Mode.PARALLEL_TOOLS)\n",
    "\n",
    "\n",
    "async def generate_parallel_tool_calls(query: str, sem: Semaphore):\n",
    "    async with sem:\n",
    "        start = time.time()\n",
    "        resp = await client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You must always use tools\"},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": query,\n",
    "                },\n",
    "            ],\n",
    "            response_model=Iterable[\n",
    "                Union[GetCalendarEvents, SendEmail, CreateReminder]\n",
    "            ],\n",
    "        )\n",
    "        end = time.time()\n",
    "\n",
    "        try:\n",
    "            tools = [tool for tool in resp]\n",
    "        except Exception:\n",
    "            tools = []\n",
    "\n",
    "        return {\n",
    "            \"response\": tools,\n",
    "            \"time\": end - start,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "tests = [\n",
    "    # Single tool queries\n",
    "    [\"Send an email to john@example.com about the project update\", [SendEmail]],\n",
    "    [\"What meetings do I have scheduled for tomorrow?\", [GetCalendarEvents]],\n",
    "    [\"Set a reminder for my dentist appointment next week\", [CreateReminder]],\n",
    "    # Two tool combinations\n",
    "    [\n",
    "        \"Check my calendar for next week's meetings and set reminders for each one\",\n",
    "        [GetCalendarEvents, CreateReminder],\n",
    "    ],\n",
    "    [\n",
    "        \"Look up my team meeting schedule and send the agenda to all participants\",\n",
    "        [GetCalendarEvents, SendEmail],\n",
    "    ],\n",
    "    [\n",
    "        \"Set a reminder for the client call and send a confirmation email to the team\",\n",
    "        [CreateReminder, SendEmail],\n",
    "    ],\n",
    "]\n",
    "\n",
    "sem = asyncio.Semaphore(10)\n",
    "coros = [generate_parallel_tool_calls(query, sem) for query, _ in tests]\n",
    "\n",
    "results = await asyncio.gather(*coros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>expected</th>\n",
       "      <th>actual</th>\n",
       "      <th>time</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>CORRECT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Send an email to john@example.com about the pr...</td>\n",
       "      <td>[SendEmail]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What meetings do I have scheduled for tomorrow?</td>\n",
       "      <td>[GetCalendarEvents]</td>\n",
       "      <td>[GetCalendarEvents]</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Set a reminder for my dentist appointment next...</td>\n",
       "      <td>[CreateReminder]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Check my calendar for next week's meetings and...</td>\n",
       "      <td>[GetCalendarEvents, CreateReminder]</td>\n",
       "      <td>[GetCalendarEvents]</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Look up my team meeting schedule and send the ...</td>\n",
       "      <td>[GetCalendarEvents, SendEmail]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Set a reminder for the client call and send a ...</td>\n",
       "      <td>[CreateReminder, SendEmail]</td>\n",
       "      <td>[SendEmail, CreateReminder]</td>\n",
       "      <td>2.81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Send an email to john@example.com about the pr...   \n",
       "1    What meetings do I have scheduled for tomorrow?   \n",
       "2  Set a reminder for my dentist appointment next...   \n",
       "3  Check my calendar for next week's meetings and...   \n",
       "4  Look up my team meeting schedule and send the ...   \n",
       "5  Set a reminder for the client call and send a ...   \n",
       "\n",
       "                              expected                       actual  time  \\\n",
       "0                          [SendEmail]                           []  0.89   \n",
       "1                  [GetCalendarEvents]          [GetCalendarEvents]  1.90   \n",
       "2                     [CreateReminder]                           []  1.26   \n",
       "3  [GetCalendarEvents, CreateReminder]          [GetCalendarEvents]  1.64   \n",
       "4       [GetCalendarEvents, SendEmail]                           []  1.63   \n",
       "5          [CreateReminder, SendEmail]  [SendEmail, CreateReminder]  2.81   \n",
       "\n",
       "   precision  recall CORRECT  \n",
       "0        0.0     0.0       N  \n",
       "1        1.0     1.0       Y  \n",
       "2        0.0     0.0       N  \n",
       "3        1.0     0.5       N  \n",
       "4        0.0     0.0       N  \n",
       "5        1.0     1.0       Y  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"query\": test_item[0],\n",
    "            \"expected\": [tool.__name__ for tool in test_item[1]],\n",
    "            \"actual\": list(set([type(tool).__name__ for tool in result[\"response\"]])),\n",
    "            \"time\": round(result[\"time\"], 2),\n",
    "        }\n",
    "        for test_item, result in zip(tests, results)\n",
    "    ]\n",
    ")\n",
    "df = calculate_precision_recall_for_queries(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tool</th>\n",
       "      <th>actual</th>\n",
       "      <th>expected</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SendEmail</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CreateReminder</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GetCalendarEvents</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tool  actual  expected  recall\n",
       "0          SendEmail       1         3    0.33\n",
       "1     CreateReminder       1         3    0.33\n",
       "2  GetCalendarEvents       2         3    0.67"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_per_tool_recall(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recall       0.42\n",
       "precision    0.50\n",
       "time         1.69\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"recall\", \"precision\", \"time\"]].mean().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we showed how precision and recall metrics can be used as objective metrics of a model's tool selection abilities. Looking at our experiment results below, we found that while parallel tool calling reduced average execution time by ~9%, it came with significant tradeoffs. We saw ~50% drop in both precision and recall.\n",
    "\n",
    "\n",
    "| Metric        | Tool Calling (Baseline) | Parallel Tool Calling |\n",
    "|---------------|-------------------------|----------------------|\n",
    "| **Precision** | 1.00                   | 0.50  ( -50% )       |\n",
    "| **Recall**    | 0.83                   | 0.42  ( -49% )       |\n",
    "| **Avg Time**  | 1.86                   | 1.69  ( -9% )        |\n",
    "\n",
    "Just as Week 1 established quick, objective metrics for retrieval quality, we've shown how similar principles apply to tool selection. Rather than evaluating complex tool executions, we can rapidly prototype and improve selection logic using simple binary metrics. This lets us identify issues early - like our model's difficulty combining multiple tools - before investing in more complex infrastructure.\n",
    "\n",
    "In the next notebook, we'll scale this evaluation framework from our test case of 3-4 tools to handle a real world application with 70 tools to call. We'll show how to dynamically provide these tool options using a yaml configuration and how to generate synthetic test data to cover different tool combinations and edge cases.\n",
    "\n",
    "With clear metrics in place, evaluating the impact of techniques like few-shot examples and improved prompts on tool selection accuracy becomes easy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
